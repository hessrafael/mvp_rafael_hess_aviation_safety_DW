{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18cb89dc-0a99-4386-9d77-d75aa7fcdccd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Definindo funções da camada Gold a serem utilizadas entre notebooks\n",
    "'''\n",
    "from pyspark.sql import functions as F\n",
    "import datetime as dt\n",
    "\n",
    "# Funções de Teste\n",
    "\n",
    "def assert_dataframes(df1, col1, df2, col2):\n",
    "    print(f\"Comparando a coluna {col1} do DF1 com {col2} do DF\")\n",
    "    # Cria um DataFrame com os valores distintos da coluna do segundo DataFrame\n",
    "    df2_values = df2.select(col2).distinct()\n",
    "    \n",
    "    # Adiciona uma coluna indicando se o valor da coluna do primeiro DataFrame está na lista de valores do segundo DataFrame\n",
    "    comparison = df1.withColumn(\n",
    "        \"is_in_second_dataframe\",\n",
    "        F.when(\n",
    "            F.col(col1).isNull() | F.col(col1).isin([row[col2] for row in df2_values.collect()]), \n",
    "            F.lit(True)\n",
    "        ).otherwise(F.lit(False))\n",
    "    )\n",
    "    \n",
    "    # Conta o número de registros onde a condição não é atendida\n",
    "    invalid_count = comparison.filter(F.col(\"is_in_second_dataframe\") == F.lit(False)).count()\n",
    "    \n",
    "    # Lança uma exceção se houver registros inválidos\n",
    "    assert invalid_count == 0, f\"Existem {invalid_count} registros em '{col1}' que não estão presentes em '{col2}' e não são NULL\"\n",
    "\n",
    "\n",
    "def test_col_not_null(df, col_name):\n",
    "    print(f\"Avaliando a condição {col_name} não contem nulos\")\n",
    "    # Filtra linhas onde a coluna é nula\n",
    "    null_count = df.filter(F.col(col_name).isNull()).count()\n",
    "    \n",
    "    # Verifica se o número de valores nulos é zero\n",
    "    assert null_count == 0, f\"Coluna {col_name} contém valores null\"\n",
    "\n",
    "def test_biggest_date_before_current_date(df, col_name):\n",
    "    print(f\"Avaliando a condição {col_name} menor que a data atual\")\n",
    "    # Obter a data atual\n",
    "    current_date = F.current_date()\n",
    "\n",
    "    # Obter a maior data na coluna especificada\n",
    "    max_date = df.agg(F.max(col_name)).collect()[0][0]\n",
    "    \n",
    "    if isinstance(max_date, str):\n",
    "        max_date = dt.datetime.strptime(max_date,'%Y%m%d').date()\n",
    "    \n",
    "    # Verificar se a maior data é antes da data atual\n",
    "    assert max_date <= df.select(current_date).collect()[0][0], f\"A maior data na coluna {col_name} é posterior a data atual\"\n",
    "\n",
    "\n",
    "def test_value_range(df, col_name, condition):\n",
    "    df_filtered = df.filter(F.expr(f\"{col_name} {condition}\"))\n",
    "    print(f\"Avaliando a condição {col_name} {condition}\")\n",
    "    #df_filtered.display()\n",
    "    assert df.count() == df_filtered.count(), f\"Os dados da coluna {col_name} não atendem a condição {condition}\"\n",
    "\n",
    "\n",
    "def test_weekday(df, col_name):\n",
    "    print(f\"Avaliando a condição {col_name} está dentre os valores aceitos para o dia de semana\")\n",
    "    # Obter os valores distintos da coluna\n",
    "    distinct_values = df.select(col_name).distinct().collect()\n",
    "    \n",
    "    # Converter os valores distintos para uma lista de strings\n",
    "    distinct_values_list = [row[col_name] for row in distinct_values]\n",
    "    \n",
    "    # Lista de dias da semana\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    \n",
    "    # Verificar se todos os valores distintos estão na lista de dias da semana\n",
    "    for value in distinct_values_list:\n",
    "        assert value in weekdays, f\"Os dados da coluna {col_name} não correspondem a dias de semana: {value}\"\n",
    "\n",
    "def test_IATA_codes(df, col_name):\n",
    "    print(f\"Avaliando a condição {col_name} contem 3 caracteres\")\n",
    "    nb_different = df.filter(F.length(F.col(col_name)) != 3).count()\n",
    "    assert nb_different == 0, \"Existem códigos IATA além de 3 dígitos\"\n",
    "\n",
    "def test_ICAO_codes(df, col_name):\n",
    "    print(f\"Avaliando a condição {col_name} contem 4 caracteres\")\n",
    "    nb_different = df.filter(F.length(F.col(col_name)) != 4).count()\n",
    "    assert nb_different == 0, \"Existem códigos IATA além de 4 dígitos\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "shared_gold_functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
